{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import glob\n",
    "from os import path\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_name(path_to_files):\n",
    "    names = []\n",
    "    for file in glob.glob(path_to_files):\n",
    "        names.append(path.splitext(path.basename(file))[0])\n",
    "    return names\n",
    "\n",
    "def load_data(path):\n",
    "    df = pd.read_csv(path, compression= \"zip\")\n",
    "    df_searched = df.query(\"search_conducted == True\")\n",
    "    df_searched[\"date\"] = pd.to_datetime(df_searched[\"date\"])\n",
    "    df_searched[\"year\"] = df_searched[\"date\"].dt.year\n",
    "    df_searched = df_searched.query('year >= 2009 and year <= 2016')\n",
    "    #df_searched['county_name'] = df_searched['county_name'].str[:-7]\n",
    "    return df_searched\n",
    "\n",
    "def compute_hit_rate_one_object(df, county, city, object = 'ethnicity'):    \n",
    "    if object == 'ethnicity':\n",
    "        df_searched_cleaned = df[['year', 'subject_race', 'search_conducted', 'contraband_found']]\n",
    "        df_searched_cleaned = df_searched_cleaned.query(\"subject_race == 'white' | subject_race == 'black'| subject_race == 'asian/pacific islander'\\\n",
    "            | subject_race == 'hispanic'\")\n",
    "        found = pd.DataFrame(df_searched_cleaned.groupby(['year', 'subject_race'])['contraband_found'].value_counts()).rename(columns={'contraband_found' : 'nb_find'}).reset_index()\n",
    "        all = pd.DataFrame(df_searched_cleaned.groupby(['year', 'subject_race'])['search_conducted'].value_counts()).rename(columns={'search_conducted' : 'nb_search'}).reset_index()\n",
    "        found_and_all = pd.merge(left = found, right = all, left_on=['year','subject_race'], right_on = ['year', 'subject_race']).drop(['search_conducted'], axis = 1)\n",
    "        found_and_all['Hit_rate'] = found_and_all['nb_find'] / found_and_all['nb_search'] * 100\n",
    "        found_and_all['County'] = county\n",
    "        found_and_all['City'] = city\n",
    "    else :\n",
    "        df_searched_cleaned = df[['year', 'subject_sex', 'search_conducted', 'contraband_found']]\n",
    "        found = pd.DataFrame(df_searched_cleaned.groupby(['year', 'subject_sex'])['contraband_found'].value_counts()).rename(columns={'contraband_found' : 'nb_find'}).reset_index()\n",
    "        all = pd.DataFrame(df_searched_cleaned.groupby(['year', 'subject_sex'])['search_conducted'].value_counts()).rename(columns={'search_conducted' : 'nb_search'}).reset_index()\n",
    "        found_and_all = pd.merge(left = found, right = all, left_on=['year','subject_sex'], right_on = ['year', 'subject_sex']).drop(['search_conducted'], axis = 1)\n",
    "        found_and_all['Hit_rate'] = found_and_all['nb_find'] / found_and_all['nb_search'] * 100\n",
    "        found_and_all['County'] = county\n",
    "        found_and_all['City'] = city\n",
    "        \n",
    "    return found_and_all.query('contraband_found == True')\n",
    "\n",
    "def compute_hit_rate_one_city(path,county, city):\n",
    "    df = load_data('../data/city/'+path +'.zip')\n",
    "    df_ethnicity = compute_hit_rate_one_object(df,county,city)\n",
    "    df_gender = compute_hit_rate_one_object(df,county,city, object = 'gender')\n",
    "    return df_ethnicity, df_gender\n",
    "\n",
    "def compute_hit_rate_multiple_cities(path_to_folder):\n",
    "    file_names = get_files_name(path_to_folder)\n",
    "    hit_rate_ethnicity, hit_rate_gender = compute_hit_rate_one_city(file_names[0], file_names[0][0:2], file_names[0][3:-4]) \n",
    "    for i in range(1,len(file_names)):\n",
    "        new_city_ethnicity, new_city_gender = compute_hit_rate_one_city(file_names[i],file_names[i][0:2] , file_names[0][3:-4])\n",
    "        hit_rate_ethnicity = pd.concat([hit_rate_ethnicity, new_city_ethnicity])\n",
    "        hit_rate_gender = pd.concat([hit_rate_gender, new_city_gender])\n",
    "    return hit_rate_ethnicity, hit_rate_gender\n",
    "\n",
    "def filter_not_duplicate(df, object = 'ethni'):\n",
    "    if object == 'ethni':\n",
    "        dupli = pd.DataFrame(df.groupby(['year'])['subject_race'].value_counts()).rename(columns={'subject_race' : 'dupli'}).reset_index()\n",
    "        test = pd.merge(left=df, right=dupli, left_on = ['year','subject_race'], right_on = ['year', 'subject_race'])\n",
    "        df = test.query('dupli == 1')\n",
    "        if(len(df)!= 0):\n",
    "            test.loc[df.index[0] + 0.5] = [df.values[0][0],df.values[0][1],'tx',0,0,2]                                 # Append list at the bottom\n",
    "            test = test.sort_index().reset_index(drop = True)\n",
    "    else :\n",
    "        dupli = pd.DataFrame(df.groupby(['year'])['subject_sex'].value_counts()).rename(columns={'subject_sex' : 'dupli'}).reset_index()\n",
    "        test = pd.merge(left=df, right=dupli, left_on = ['year','subject_sex'], right_on = ['year', 'subject_sex'])\n",
    "        df = test.query('dupli == 1')\n",
    "        if(len(df) !=0):\n",
    "            test.loc[df.index[0] + 0.5] = [df.values[0][0],df.values[0][1],'tx',0,0,2]                                 # Append list at the bottom\n",
    "            test = test.sort_index().reset_index(drop = True)\n",
    "    return test\n",
    "\n",
    "def compute_mean_hit_rate_by_state(path_to_folder):\n",
    "    hit_rate_ethnicity, hit_rate_gender = compute_hit_rate_multiple_cities(path_to_folder)\n",
    "    all_city_gender_mean_hit_rate = hit_rate_gender.groupby(['year', 'subject_sex', 'County'])['Hit_rate'].agg(['mean']).reset_index()\n",
    "    all_city_gender_mean_search_count = hit_rate_gender.groupby(['year', 'subject_sex'])['nb_search'].agg(['sum']).reset_index()\n",
    "    hit_rate_gender_mean = pd.merge(all_city_gender_mean_hit_rate, all_city_gender_mean_search_count, left_on=['year', 'subject_sex'], right_on=['year', 'subject_sex'])\n",
    "    all_city_ethnicity_mean_hit_rate = hit_rate_ethnicity.groupby(['year', 'subject_race', 'County'])['Hit_rate'].agg(['mean']).reset_index()\n",
    "    all_city_ethnicity_mean_search_count = hit_rate_ethnicity.groupby(['year', 'subject_race'])['nb_search'].agg(['sum']).reset_index()\n",
    "    hit_rate_ethnicity_mean = pd.merge(all_city_ethnicity_mean_hit_rate, all_city_ethnicity_mean_search_count, left_on=['year', 'subject_race'], right_on=['year', 'subject_race'])\n",
    "    return filter_not_duplicate(hit_rate_ethnicity_mean), filter_not_duplicate(hit_rate_gender_mean, object = 'gender'), hit_rate_ethnicity, hit_rate_gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_rate_ethnicity_mean, hit_rate_gender_mean, hit_rate_ethnicity, hit_rate_gender = compute_mean_hit_rate_by_state('../data/city/*.csv.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_rate_ethnicity.to_csv('../data/city/all_hit_rate_ethnicity.csv')\n",
    "hit_rate_gender.to_csv('../data/city/all_hit_rate_gender.csv')\n",
    "hit_rate_ethnicity_mean.to_csv('../data/city/all_hit_rate_ethnicity_mean.csv')\n",
    "hit_rate_gender_mean.to_csv('../data/city/all_hit_rate_gender_mean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>subject_race</th>\n",
       "      <th>County</th>\n",
       "      <th>mean</th>\n",
       "      <th>sum</th>\n",
       "      <th>dupli</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009.0</td>\n",
       "      <td>asian/pacific islander</td>\n",
       "      <td>ca</td>\n",
       "      <td>35.416667</td>\n",
       "      <td>394</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009.0</td>\n",
       "      <td>asian/pacific islander</td>\n",
       "      <td>tx</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>394</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009.0</td>\n",
       "      <td>black</td>\n",
       "      <td>ca</td>\n",
       "      <td>8.663283</td>\n",
       "      <td>3278</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009.0</td>\n",
       "      <td>black</td>\n",
       "      <td>tx</td>\n",
       "      <td>22.910217</td>\n",
       "      <td>3278</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009.0</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>ca</td>\n",
       "      <td>6.004367</td>\n",
       "      <td>2271</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2009.0</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>tx</td>\n",
       "      <td>27.790433</td>\n",
       "      <td>2271</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2009.0</td>\n",
       "      <td>white</td>\n",
       "      <td>ca</td>\n",
       "      <td>19.283747</td>\n",
       "      <td>2348</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2009.0</td>\n",
       "      <td>white</td>\n",
       "      <td>tx</td>\n",
       "      <td>23.076923</td>\n",
       "      <td>2348</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2010.0</td>\n",
       "      <td>asian/pacific islander</td>\n",
       "      <td>ca</td>\n",
       "      <td>37.328767</td>\n",
       "      <td>316</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2010.0</td>\n",
       "      <td>asian/pacific islander</td>\n",
       "      <td>tx</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>316</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2010.0</td>\n",
       "      <td>black</td>\n",
       "      <td>ca</td>\n",
       "      <td>8.883354</td>\n",
       "      <td>2839</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2010.0</td>\n",
       "      <td>black</td>\n",
       "      <td>tx</td>\n",
       "      <td>23.720930</td>\n",
       "      <td>2839</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2010.0</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>ca</td>\n",
       "      <td>11.665005</td>\n",
       "      <td>1705</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2010.0</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>tx</td>\n",
       "      <td>23.504274</td>\n",
       "      <td>1705</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2010.0</td>\n",
       "      <td>white</td>\n",
       "      <td>ca</td>\n",
       "      <td>27.635135</td>\n",
       "      <td>2038</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2010.0</td>\n",
       "      <td>white</td>\n",
       "      <td>tx</td>\n",
       "      <td>22.759857</td>\n",
       "      <td>2038</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2011.0</td>\n",
       "      <td>asian/pacific islander</td>\n",
       "      <td>ca</td>\n",
       "      <td>28.009828</td>\n",
       "      <td>417</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2011.0</td>\n",
       "      <td>asian/pacific islander</td>\n",
       "      <td>tx</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>417</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2011.0</td>\n",
       "      <td>black</td>\n",
       "      <td>ca</td>\n",
       "      <td>5.999302</td>\n",
       "      <td>3538</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2011.0</td>\n",
       "      <td>black</td>\n",
       "      <td>tx</td>\n",
       "      <td>27.421759</td>\n",
       "      <td>3538</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2011.0</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>ca</td>\n",
       "      <td>7.008671</td>\n",
       "      <td>2360</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2011.0</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>tx</td>\n",
       "      <td>28.995902</td>\n",
       "      <td>2360</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2011.0</td>\n",
       "      <td>white</td>\n",
       "      <td>ca</td>\n",
       "      <td>21.572872</td>\n",
       "      <td>1971</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2011.0</td>\n",
       "      <td>white</td>\n",
       "      <td>tx</td>\n",
       "      <td>27.008547</td>\n",
       "      <td>1971</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2012.0</td>\n",
       "      <td>asian/pacific islander</td>\n",
       "      <td>ca</td>\n",
       "      <td>22.123894</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2012.0</td>\n",
       "      <td>asian/pacific islander</td>\n",
       "      <td>tx</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2012.0</td>\n",
       "      <td>black</td>\n",
       "      <td>ca</td>\n",
       "      <td>5.922166</td>\n",
       "      <td>3369</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2012.0</td>\n",
       "      <td>black</td>\n",
       "      <td>tx</td>\n",
       "      <td>14.343381</td>\n",
       "      <td>3369</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2012.0</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>ca</td>\n",
       "      <td>8.815166</td>\n",
       "      <td>2822</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2012.0</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>tx</td>\n",
       "      <td>16.604831</td>\n",
       "      <td>2822</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      year            subject_race County       mean   sum  dupli\n",
       "0   2009.0  asian/pacific islander     ca  35.416667   394      2\n",
       "1   2009.0  asian/pacific islander     tx  10.000000   394      2\n",
       "2   2009.0                   black     ca   8.663283  3278      2\n",
       "3   2009.0                   black     tx  22.910217  3278      2\n",
       "4   2009.0                hispanic     ca   6.004367  2271      2\n",
       "5   2009.0                hispanic     tx  27.790433  2271      2\n",
       "6   2009.0                   white     ca  19.283747  2348      2\n",
       "7   2009.0                   white     tx  23.076923  2348      2\n",
       "8   2010.0  asian/pacific islander     ca  37.328767   316      2\n",
       "9   2010.0  asian/pacific islander     tx  12.500000   316      2\n",
       "10  2010.0                   black     ca   8.883354  2839      2\n",
       "11  2010.0                   black     tx  23.720930  2839      2\n",
       "12  2010.0                hispanic     ca  11.665005  1705      2\n",
       "13  2010.0                hispanic     tx  23.504274  1705      2\n",
       "14  2010.0                   white     ca  27.635135  2038      2\n",
       "15  2010.0                   white     tx  22.759857  2038      2\n",
       "16  2011.0  asian/pacific islander     ca  28.009828   417      2\n",
       "17  2011.0  asian/pacific islander     tx  30.000000   417      2\n",
       "18  2011.0                   black     ca   5.999302  3538      2\n",
       "19  2011.0                   black     tx  27.421759  3538      2\n",
       "20  2011.0                hispanic     ca   7.008671  2360      2\n",
       "21  2011.0                hispanic     tx  28.995902  2360      2\n",
       "22  2011.0                   white     ca  21.572872  1971      2\n",
       "23  2011.0                   white     tx  27.008547  1971      2\n",
       "24  2012.0  asian/pacific islander     ca  22.123894   226      1\n",
       "25  2012.0  asian/pacific islander     tx   0.000000     0      2\n",
       "26  2012.0                   black     ca   5.922166  3369      2\n",
       "27  2012.0                   black     tx  14.343381  3369      2\n",
       "28  2012.0                hispanic     ca   8.815166  2822      2\n",
       "29  2012.0                hispanic     tx  16.604831  2822      2"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hit_rate_ethnicity_mean.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ee784ad58132e9462f1f8cf86dca212ca28d7fa75053eeffe69366db508fdd8a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('ada')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
